# ResumeAI â€“ Automated Resume Screening Platform

A modern, roleâ€‘aware resume screening and jobâ€‘matching platform for students and job seekers, with recruiter tools. Built to deliver **resume parsing, roleâ€‘specific scoring, JD matching, AI rewrite suggestions, gamification, and an optional recruiter dashboard**.

---

## ğŸ”¥ Why this project

Most tools give a generic score. **ResumeAI** focuses on **roleâ€‘specific feedback + instant improvements** and grows into a **career ecosystem** (learning recommendations, mock interviews, verified portfolios) while also serving **recruiters**.

---
we as a team start the project with this and current plan for the project is this 

## âœ¨ Core Features (MVP â†’ Advanced)

**MVP (Phase 1)**

* User auth (signup/login, JWT)
* Profile (role/industry preference)
* Resume upload (PDF/DOC/DOCX) & parsing
* Basic scoring (structure, grammar, keywords per role)
* Actionable feedback cards

**Phase 2 â€“ Differentiators**

* JD (Job Description) matching & match %
* AI resume rewriter (bullet improvements)
* Roleâ€‘specific rubrics (e.g., SDE, DS, Marketing)

**Phase 3 â€“ Ecosystem**

* Portfolio links (GitHub/Kaggle/Behance/LinkedIn) + activity signals
* Learning recommendations (fill skill gaps)
* Gamification (badges, leaderboards)

**Phase 4 â€“ Premium/Recruiter**

* AI mock interviews tied to resume
* Recruiter dashboard (bulk upload, ranked shortlist)
* Browser extension for job boards (instant match %)

---

## ğŸ—ï¸ Architecture (suggested)

```
frontend/        React + Vite + Tailwind (TypeScript)
backend/         Node.js + Express (TypeScript) â€“ Auth, Users, Uploads, Scoring orchestrator
nlp-service/     (Optional) Python + FastAPI â€“ parsing, JD matching, NER, keyword/scoring
worker/          (Optional) BullMQ/Redis â€“ async parsing & scoring jobs
shared/          Shared types/schemas (Zod), constants, rubrics
infra/           Docker Compose, GitHub Actions, env templates
```

**Storage & DB**: MongoDB (users, resumes, scores, JDs, feedback, recruiter jobs)
**File storage**: Local `/uploads` (dev) â†’ S3/Cloud Storage (prod)
**Queue**: Redis (optional) for heavy parsing/scoring
**Observability**: pino logs + OpenTelemetry (optional)

---

## ğŸ§° Tech Stack

* **Frontend**: React, Vite, TypeScript, Tailwind, shadcn/ui, React Query, React Router
* **Backend**: Node.js, Express, TypeScript, Zod, Mongoose, Multer, JWT, bcrypt
* **NLP** (optional service): Python, FastAPI, spaCy, scikitâ€‘learn, sentenceâ€‘transformers
* **DB/Infra**: MongoDB, Redis (optional), Docker, Docker Compose, GitHub Actions CI

---

## ğŸ“ Folder Structure (starter)

```
resumeai/
â”œâ”€ frontend/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ pages/ (Home, Features, Pricing, Login, Dashboard)
â”‚  â”‚  â”œâ”€ lib/ (api.ts, queryClient.ts)
â”‚  â”‚  â”œâ”€ hooks/
â”‚  â”‚  â”œâ”€ routes/
â”‚  â”‚  â””â”€ main.tsx
â”‚  â”œâ”€ index.html
â”‚  â”œâ”€ package.json
â”‚  â””â”€ vite.config.ts
â”œâ”€ backend/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ app.ts (express app)
â”‚  â”‚  â”œâ”€ server.ts (boot)
â”‚  â”‚  â”œâ”€ config/
â”‚  â”‚  â”œâ”€ middlewares/
â”‚  â”‚  â”œâ”€ modules/
â”‚  â”‚  â”‚  â”œâ”€ auth/ (routes, controller, service)
â”‚  â”‚  â”‚  â”œâ”€ users/
â”‚  â”‚  â”‚  â”œâ”€ resumes/ (upload, parse, score)
â”‚  â”‚  â”‚  â””â”€ jobs/ (JD upload/match)
â”‚  â”‚  â”œâ”€ utils/
â”‚  â”‚  â””â”€ types/
â”‚  â”œâ”€ package.json
â”‚  â””â”€ tsconfig.json
â”œâ”€ nlp-service/ (optional)
â”‚  â”œâ”€ app.py (FastAPI)
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ models/ (keyword lists, embeddings)
â”œâ”€ shared/
â”‚  â”œâ”€ rubrics/
â”‚  â”‚  â”œâ”€ sde.json
â”‚  â”‚  â”œâ”€ data-science.json
â”‚  â”‚  â””â”€ marketing.json
â”‚  â””â”€ schemas/ (zod/ts)
â”œâ”€ infra/
â”‚  â”œâ”€ docker-compose.yml
â”‚  â”œâ”€ .env.example
â”‚  â””â”€ ci.yml (GitHub Actions)
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ Getting Started

### Prerequisites

* Node.js â‰¥ 18, npm or pnpm
* Python â‰¥ 3.10 (if using `nlp-service`)
* Docker Desktop (optional, for DB/services)

### 1) Clone & env setup

```bash
git clone https://github.com/<your-username>/resumeai.git
cd resumeai
cp infra/.env.example .env # for root orchestration
```

### 2) Start with Docker (quickest)

```bash
docker compose -f infra/docker-compose.yml up -d
```

This brings up: MongoDB, Redis (optional), backend, frontend, and nlp-service (if enabled).

### 3) Run manually (dev mode)

**Backend**

```bash
cd backend
cp ../infra/.env.example .env
npm i
npm run dev
```

**Frontend**

```bash
cd frontend
npm i
npm run dev
```

**NLP Service (optional)**

```bash
cd nlp-service
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn app:app --reload --port 8001
```

---

## ğŸ” Environment Variables

Create `.env` files in `backend/`, `frontend/`, and `nlp-service/` as needed.

**backend/.env**

```
PORT=8000
MONGO_URI=mongodb://localhost:27017/resumeai
JWT_SECRET=supersecret
UPLOAD_DIR=./uploads
NLP_SERVICE_URL=http://localhost:8001
ALLOWED_ORIGINS=http://localhost:5173
```

**frontend/.env**

```
VITE_API_BASE=http://localhost:8000/api
```

**nlp-service/.env** (optional)

```
PORT=8001
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

---

## ğŸ§ª API (initial draft)

Base URL: `/api`

### Auth

* `POST /auth/signup` â€“ { name, email, password, rolePreference }
* `POST /auth/login` â€“ { email, password }
* `GET /auth/me` â€“ Get current user

### Resume

* `POST /resumes` â€“ multipart upload; returns { resumeId }
* `GET /resumes/:id` â€“ metadata + latest score
* `GET /resumes/:id/feedback` â€“ array of feedback items

### JD Matching

* `POST /jobs/jd` â€“ upload JD text; returns { jdId }
* `POST /match` â€“ { resumeId, jdId } â†’ { matchPct, missingKeywords\[] }

### AI Rewrite

* `POST /resumes/:id/rewrite` â€“ { bulletText } â†’ { improvedBullet }

---

## ğŸ—ƒï¸ Data Models (simplified)

**User**

```ts
{
  _id: ObjectId,
  name: string,
  email: string,
  passwordHash: string,
  rolePreference: 'sde' | 'data-science' | 'marketing' | ...,
  badges: string[],
  createdAt, updatedAt
}
```

**Resume**

```ts
{
  _id: ObjectId,
  userId: ObjectId,
  filename: string,
  text: string,
  sections: { education, experience[], projects[], skills[] },
  latestScore: number,
  rubricId: string,
  createdAt, updatedAt
}
```

**JD**

```ts
{
  _id: ObjectId,
  employer?: ObjectId,
  title: string,
  text: string,
  requiredSkills: string[],
  niceToHave: string[],
  createdAt
}
```

**MatchResult**

```ts
{
  resumeId: ObjectId,
  jdId: ObjectId,
  matchPct: number,
  missingKeywords: string[],
  ts: Date
}
```

---

## ğŸ“ Scoring Rubric (starter idea)

Weights can be tuned per role.

```
Structure (20): required sections present, ordering
Clarity (15): grammar, readability, action verbs
Impact (25): metrics, outcomes, ownership
Skills (20): hard skills vs role rubric (Zod/JSON)
Projects (10): relevance, recency, repo links
ATSâ€‘friendliness (10): headings, fonts, no tables/images
```

Example rubric JSON: `shared/rubrics/sde.json`

```json
{
  "weights": {"structure": 0.2, "clarity": 0.15, "impact": 0.25, "skills": 0.2, "projects": 0.1, "ats": 0.1},
  "keywords": ["data structures", "algorithms", "git", "rest api", "docker", "aws"],
  "penalties": {"tables": 5, "images": 5, "excess_pages": 10}
}
```

---

## ğŸ§  JD Matching (approach)

* Extract skills/entities â†’ spaCy NER + curated keyword lists.
* Compute embeddings for resume vs JD â†’ cosine similarity (sentenceâ€‘transformers).
* Weighted score = keyword overlap (40%) + embedding similarity (60%).

---

## ğŸ§© Frontend UX Notes

* Sticky header that shrinks on scroll (logo centers on midâ€‘scroll)
* Pages: Home, Features, Pricing, How It Works, Login/Register, Dashboard
* Dashboard: Upload resume â†’ Score + Feedback + Rewrite â†’ JD Match â†’ Share/Export
* Gamification widgets: Score history chart, badges grid, college leaderboard

---

## ğŸ§± Security & Privacy

* Hash passwords (bcrypt), sign JWTs, rotate tokens
* Validate inputs with Zod; sanitize file uploads (Multer limits, MIME checks)
* Store files privately; generate signed URLs for downloads
* PII minimization; allow users to delete data (GDPRâ€‘style)

---

## ğŸš€ Scripts

**Frontend**

```bash
npm run dev    # start vite dev server
npm run build  # production build
```

**Backend**

```bash
npm run dev    # ts-node-dev
npm run build  # tsc
npm run start  # node dist/server.js
```

**NLP Service**

```bash
uvicorn app:app --reload --port 8001
```
---

## ğŸ¤ Contributing

1. Fork & clone
2. Create a feature branch: `feat/<scope>`
3. Commit with Conventional Commits (e.g., `feat(auth): add jwt refresh`)
4. PR to `main` with description & screenshots

**Commit types**: feat, fix, docs, style, refactor, perf, test, chore, ci

---

## ğŸ§ª CI/CD (GitHub Actions)

* Lint & typecheck on PR
* Run unit tests
* Build Docker images on `main`
* Optional: Deploy to Render/Vercel/Fly.io

---

## ğŸ“„ License

MIT â€“ free to use and modify.

---

## ğŸ“š Starter Tasks for New Contributors

* [ ] Implement `/auth/signup` & `/auth/login`
* [ ] Build upload endpoint (Multer) & PDF/DOCX parser
* [ ] Create `shared/rubrics/sde.json` & apply during scoring
* [ ] Frontend Upload â†’ Score view with feedback cards
* [ ] JD Match UI: paste JD â†’ get match % + missing keywords

---

## ğŸ§ª Sample Data & Testing

* Add `samples/` with 3 resumes (SDE/DS/Marketing) + 2 JDs for quick testing.
* Seed script to create demo users and mock scores.

---

## ğŸ™Œ Credits

Built by Piyush Dubey ,shubham singh , sakshi kumari and anisha . 
PRs welcome!
# Automated-ResumeScreening
